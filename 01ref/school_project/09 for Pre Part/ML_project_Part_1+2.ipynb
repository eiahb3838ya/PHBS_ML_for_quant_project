{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-term market timing strategy based on boosting ML algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Course project of Machine Learning for Finance at PHBS in 2019-2020 Module3.\n",
    "\n",
    "* Yifan Hu/Evan        1901212691  [eiahb3838ya](https://github.com/eiahb3838ya) \n",
    "* Yuting Fang/Trista   1901212576  [ytfang222](https://github.com/ytfang222) \n",
    "* Zhihao Chen/Alfred   1901212567  [AlfredChenZH](https://github.com/AlfredChenZH) \n",
    "* Zilei Wang/ Lorelei  1901212645  [LoreleiWong](https://github.com/LoreleiWong) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Motivation\n",
    "\n",
    "As the global financial market is generating mass data of different types every day, it is becoming more crucial and more **difficult to effectively extract and use these data to predict the trend of stocks**. The short term timing strategy has a few difficulties as follows:\n",
    "\n",
    "1. Market sentiments strongly influence the short-term market trend;\n",
    "2. How to extract effective factors;\n",
    "3. How to build nonlinear factors;\n",
    "4. How to solve collinearity among factors.\n",
    "\n",
    "#### 1.2 Our project goal\n",
    "\n",
    "In this project, we recognize the **price up or down** as a **classification problem** and implement several **machine learning algorithms** to predict the future price up or down of **WindA Index(Y)**([881001.csv](00%20data/881001.csv)), an index indicating the trend of Chinese A Share stocks, to build a **short-term timing strategy**.\n",
    "\n",
    "#### 1.3 Brief Summary of Dataset\n",
    "\n",
    "The X is **macroeconomic data in china**([cleanedFactor.pkl](00%20data/cleanedFactor.pkl)) plus **American index indicators**, like ([DJI.GI,NQ.CME](00%20data/AddNewData)).We also use the OHLC price of windA to **build some features(alphas)**.  \n",
    "The Y is 01 **bool value of windA** in next trade day.  \n",
    "The total number of features is 60.  \n",
    "The time period: from 20080401 to 20200306.  \n",
    "The data can be acquired from Wind Database directly. All factors are based on daily frequency data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Dataset sample\n",
    "\n",
    "![images](picture/features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Workflow\n",
    "\n",
    "![images](picture/workFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement feature selection functions and establish Myclassifiers classes using logistic regression, naive Bayes, KNN, perceptron, decision tree, SVM, XGBoost and Sequential neural network model in Keras to fit and then predict the up or down of WindA Index in the next day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Rolling Prediction \n",
    "\n",
    "As the financial data are time series data, we implement an **expanding window** training and prediction procedure as follows: \n",
    "1. We get at least 1800 days' data as the training dataset and use k-fold cross validation method to tune the hyperparameters for the best model, so the first signal we can get is the 1801 day.\n",
    "2. The signal is the predict results of the up or down of WindA Index in the next day. If the signal is predicted to be 1, then we buy WindA Index at the close of the day. If it is predicted as 0, then we short WindA or do nothing at the close of the day.\n",
    "3. We use the best model in Step 2 for 20 consecutive trading days and then add the 20 days' data into the training set in Step 1 to enter Step 1 again.\n",
    "\n",
    "![images](picture/rollingprediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART2 Data Preprocessing & Feature Selection\n",
    "\n",
    "Actually, we download raw data from windA database in different categories,so it needs some time to concate data and handle code issues. It is really tedious so we skip this part in pre.  \n",
    "Really thanks to Evan doing this patiently and carefully ：） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Tackle with NaN \n",
    "\n",
    "Then we compute the number of NaN in each factor, as shown in the following image. After dropping all NaN including non-trading day data and other missing data, we get a dataframe including 2,903 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IBO001</th>\n",
       "      <th>R007</th>\n",
       "      <th>B0</th>\n",
       "      <th>IBO001_pctChange5</th>\n",
       "      <th>R007_pctChange5</th>\n",
       "      <th>B0_pctChange5</th>\n",
       "      <th>SHIBORO/N</th>\n",
       "      <th>SHIBOR1W</th>\n",
       "      <th>SHIBOR2W</th>\n",
       "      <th>SHIBOR1M</th>\n",
       "      <th>...</th>\n",
       "      <th>ETFVolatility120</th>\n",
       "      <th>ETFVolatility60_pctChange5</th>\n",
       "      <th>ETFVolatility120_pctChange5</th>\n",
       "      <th>mktVolume</th>\n",
       "      <th>mktVolume_pctChange5</th>\n",
       "      <th>mktClose_pctChange5</th>\n",
       "      <th>ETFReturn</th>\n",
       "      <th>ETFTomorrowUp</th>\n",
       "      <th>windAReturn</th>\n",
       "      <th>windATomorrowUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-09-03</th>\n",
       "      <td>1.8289</td>\n",
       "      <td>2.4612</td>\n",
       "      <td>2.4713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8197</td>\n",
       "      <td>2.4963</td>\n",
       "      <td>2.7768</td>\n",
       "      <td>2.9081</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.934243e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-04</th>\n",
       "      <td>1.8828</td>\n",
       "      <td>2.1780</td>\n",
       "      <td>2.1805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8860</td>\n",
       "      <td>2.2348</td>\n",
       "      <td>2.7740</td>\n",
       "      <td>2.9625</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.833770e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009198</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-05</th>\n",
       "      <td>1.8201</td>\n",
       "      <td>2.3618</td>\n",
       "      <td>2.3678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8122</td>\n",
       "      <td>2.3683</td>\n",
       "      <td>2.9631</td>\n",
       "      <td>3.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494567e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-06</th>\n",
       "      <td>1.8173</td>\n",
       "      <td>2.4748</td>\n",
       "      <td>2.4389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8198</td>\n",
       "      <td>2.4385</td>\n",
       "      <td>3.2259</td>\n",
       "      <td>3.2956</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626460e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-07</th>\n",
       "      <td>2.0160</td>\n",
       "      <td>2.8528</td>\n",
       "      <td>2.8629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0446</td>\n",
       "      <td>2.8066</td>\n",
       "      <td>3.5218</td>\n",
       "      <td>3.4738</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.825542e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IBO001    R007      B0  IBO001_pctChange5  R007_pctChange5  \\\n",
       "date                                                                     \n",
       "2007-09-03  1.8289  2.4612  2.4713                NaN              NaN   \n",
       "2007-09-04  1.8828  2.1780  2.1805                NaN              NaN   \n",
       "2007-09-05  1.8201  2.3618  2.3678                NaN              NaN   \n",
       "2007-09-06  1.8173  2.4748  2.4389                NaN              NaN   \n",
       "2007-09-07  2.0160  2.8528  2.8629                NaN              NaN   \n",
       "\n",
       "            B0_pctChange5  SHIBORO/N  SHIBOR1W  SHIBOR2W  SHIBOR1M  ...  \\\n",
       "date                                                                ...   \n",
       "2007-09-03            NaN     1.8197    2.4963    2.7768    2.9081  ...   \n",
       "2007-09-04            NaN     1.8860    2.2348    2.7740    2.9625  ...   \n",
       "2007-09-05            NaN     1.8122    2.3683    2.9631    3.0903  ...   \n",
       "2007-09-06            NaN     1.8198    2.4385    3.2259    3.2956  ...   \n",
       "2007-09-07            NaN     2.0446    2.8066    3.5218    3.4738  ...   \n",
       "\n",
       "            ETFVolatility120  ETFVolatility60_pctChange5  \\\n",
       "date                                                       \n",
       "2007-09-03               NaN                         NaN   \n",
       "2007-09-04               NaN                         NaN   \n",
       "2007-09-05               NaN                         NaN   \n",
       "2007-09-06               NaN                         NaN   \n",
       "2007-09-07               NaN                         NaN   \n",
       "\n",
       "            ETFVolatility120_pctChange5     mktVolume  mktVolume_pctChange5  \\\n",
       "date                                                                          \n",
       "2007-09-03                          NaN  1.934243e+10                   NaN   \n",
       "2007-09-04                          NaN  1.833770e+10                   NaN   \n",
       "2007-09-05                          NaN  1.494567e+10                   NaN   \n",
       "2007-09-06                          NaN  1.626460e+10                   NaN   \n",
       "2007-09-07                          NaN  1.825542e+10                   NaN   \n",
       "\n",
       "            mktClose_pctChange5  ETFReturn  ETFTomorrowUp  windAReturn  \\\n",
       "date                                                                     \n",
       "2007-09-03                  NaN        NaN            0.0          NaN   \n",
       "2007-09-04                  NaN  -0.016827            0.0    -0.009198   \n",
       "2007-09-05                  NaN  -0.002445            1.0     0.002539   \n",
       "2007-09-06                  NaN   0.012255            0.0     0.010107   \n",
       "2007-09-07                  NaN  -0.016949            1.0    -0.021509   \n",
       "\n",
       "            windATomorrowUp  \n",
       "date                         \n",
       "2007-09-03              0.0  \n",
       "2007-09-04              1.0  \n",
       "2007-09-05              1.0  \n",
       "2007-09-06              0.0  \n",
       "2007-09-07              1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly \n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "ROOT = '../'\n",
    "FACTOR_PATH = os.path.join(ROOT, '02 data process')\n",
    "outputDir = os.path.join(ROOT, '02 data process')\n",
    "\n",
    "X_df = pd.read_pickle(os.path.join(FACTOR_PATH, 'factor.pkl'))\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import * \n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "mpl.rcParams['font.sans-serif'] = ['Microsoft YaHei'] #更新字体格式\n",
    "mpl.rcParams['font.size'] = 9 \n",
    "nas_df = X_df.isna()\n",
    "# print(X_df.isna().sum())\n",
    "\n",
    "# plt.figure(figsize = (15, 6))\n",
    "# plt.title('NaN count in data')\n",
    "# plt.xticks(rotation='vertical')\n",
    "# plt.bar(nas_df.sum().index, nas_df.sum().values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](picture/NanNumber.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国债到期收益率:6个月           29\n",
      "国债到期收益率:1年             2\n",
      "国债到期收益率:2年             1\n",
      "CRB现货指数:综合            97\n",
      "期货收盘价(连续):COMEX黄金    159\n",
      "期货结算价(连续):布伦特原油       22\n",
      "COMEX黄金/WTI原油        159\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "XDroped_df = X_df.loc['2008-04':].dropna(axis = 0, thresh=35)\n",
    "print(XDroped_df.isna().sum()[XDroped_df.isna().sum()>0])\n",
    "nas_df = XDroped_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](picture/NanNumber2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "XFilled_df = XDroped_df.fillna(method = 'ffill')\n",
    "# for date in XDroped_df.loc[XDroped_df['期货收盘价(连续):COMEX黄金'].isna()]\n",
    "# for date in XDroped_df.loc[XDroped_df['期货收盘价(连续):COMEX黄金'].isna()].index: print(date)\n",
    "XDroped_df = XDroped_df[XDroped_df['期货收盘价(连续):COMEX黄金'].isna()]\n",
    "XDroped_df = XDroped_df[XDroped_df['国债到期收益率:6个月_pctChange5'].isna()]\n",
    "XDroped_df = XDroped_df.iloc[:,25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBO001               True\n",
      "R007                 True\n",
      "B0                   True\n",
      "IBO001_pctChange5    True\n",
      "R007_pctChange5      True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "XFilled_df.head(5)\n",
    "print(np.isfinite(XFilled_df).all().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBO001 13.8284\n",
      "R007 11.6217\n",
      "B0 11.6493\n",
      "IBO001_pctChange5 2.5731317968672056\n",
      "R007_pctChange5 1.963432953826692\n",
      "B0_pctChange5 1.9480121121554133\n",
      "SHIBORO/N 13.444\n",
      "SHIBOR1W 11.004\n",
      "SHIBOR2W 9.0642\n",
      "SHIBOR1M 9.698\n",
      "SHIBOR3M 6.4611\n",
      "SHIBOR6M 5.5242\n",
      "SHIBORO/N_pctChange5 2.6073306294126484\n",
      "SHIBOR1W_pctChange5 1.875638306229869\n",
      "SHIBOR2W_pctChange5 1.5312022414671422\n",
      "SHIBOR1M_pctChange5 0.9572557847345828\n",
      "SHIBOR3M_pctChange5 0.3585700344136833\n",
      "SHIBOR6M_pctChange5 0.08224215246636768\n",
      "国债到期收益率:6个月 4.5621\n",
      "国债到期收益率:1年 4.2109\n",
      "国债到期收益率:2年 4.4507\n",
      "国债到期收益率:6个月_pctChange5 2.1164144353899887\n",
      "国债到期收益率:1年_pctChange5 0.9207119741100322\n",
      "国债到期收益率:2年_pctChange5 0.39655504234026195\n",
      "南华综合指数 1676.88\n",
      "CRB现货指数:综合 580.32\n",
      "期货收盘价(连续):COMEX黄金 1873.7\n",
      "期货结算价(连续):布伦特原油 146.08\n",
      "COMEX黄金/WTI原油 39.80631276901004\n",
      "南华综合指数_pctChange5 0.11500998794842587\n",
      "CRB现货指数:综合_pctChange5 0.054300397556482194\n",
      "期货收盘价(连续):COMEX黄金_pctChange5 0.20361137313030597\n",
      "期货结算价(连续):布伦特原油_pctChange5 0.29319781078967955\n",
      "COMEX黄金/WTI原油_pctChange5 0.2570562801310421\n",
      "标普500 23707.1134\n",
      "日经225 1539.5444\n",
      "上证综指 5166.35\n",
      "标普500_pctChange5 0.17947620556788624\n",
      "日经225_pctChange5 0.1436901335171934\n",
      "上证综指_pctChange5 0.21186631551130208\n",
      "ETFVolatility60 0.001621375544793892\n",
      "ETFVolatility120 0.0011833383111598708\n",
      "ETFVolatility60_pctChange5 2.0997327400010732\n",
      "ETFVolatility120_pctChange5 0.8919473527383452\n",
      "mktVolume 130045000000.0\n",
      "mktVolume_pctChange5 3.3757896328763826\n",
      "mktClose_pctChange5 0.17335083422935416\n",
      "ETFReturn 0.10191082802547768\n",
      "ETFTomorrowUp 1.0\n",
      "windAReturn 0.09422448232287262\n",
      "windATomorrowUp 1.0\n"
     ]
    }
   ],
   "source": [
    "for aColumn in XFilled_df.columns:\n",
    "    print(aColumn, XFilled_df[~np.isposinf(XFilled_df)].max()[aColumn])\n",
    "    XFilled_df.loc[np.isinf(XFilled_df)[aColumn], aColumn] = XFilled_df[~np.isposinf(XFilled_df)].max()[aColumn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Tackle with extreme values \n",
    "\n",
    "We use MAD method to limit feature values to the range of [median – n*MAD, median + n*MAD]. We also standardize data before training our models.\n",
    "\n",
    "Since we will roll all data in the following classifier models, it is necessary to calculate median, mean and variance of training data and testing data for each scrolling window, so we encapsulate the cutExtreme funtion to achieve standard input and output in cutting extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutExtreme(XFilled_df, n = 3.5):\n",
    "    MAD_s = XFilled_df.mad()\n",
    "    upper_s = XFilled_df.median()+n*MAD_s\n",
    "    lower_s = XFilled_df.median()-n*MAD_s\n",
    "    X_df = XFilled_df\n",
    "\n",
    "    for aColumn in X_df.columns:\n",
    "        X_df.loc[X_df[aColumn]>upper_s[aColumn], aColumn] = upper_s[aColumn]\n",
    "        X_df.loc[X_df[aColumn]<lower_s[aColumn], aColumn] = lower_s[aColumn]\n",
    "\n",
    "    XNoExtreme_df = X_df\n",
    "    return(XNoExtreme_df)\n",
    "\n",
    "XNoExtreme_df = cutExtreme(XFilled_df, n = 3.5)\n",
    "\n",
    "XNoExtreme_df.to_csv(os.path.join(outputDir, 'cleanedFactor.csv'))\n",
    "XNoExtreme_df.to_pickle(os.path.join(outputDir, 'cleanedFactor.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to install pandas_profiling first, may meet environment problem.\n",
    "# if you don't want to do this, the output result is in 07 report/inputDataReport.html\n",
    "\n",
    "# import pandas_profiling \n",
    "# X_df = pd.read_pickle('cleanedfactor.pkl')\n",
    "# profile = pandas_profiling.ProfileReport(X_df)\n",
    "# profile.to_file(outputfile=\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](picture/pearson.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](picture/spearman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 feature selection\n",
    "\n",
    "We can see that correlation among these factors are relatively high, which is easy to understand. In order to solve this problem, we adopt some particular feature selection functionss to deal with this issue as can be seen in the following part.\n",
    "\n",
    "Here we build five models to select features:\n",
    "* naiveSelection.py\n",
    "* pcaSelection.py\n",
    "* SVCL1Selection.py\n",
    "* treeSelection.py\n",
    "* varianceThresholdSelection.py\n",
    "\n",
    "To avoid high correlation among features as much as possible, we can choose LASSO in SVC model. To find the most import features, we can choose pca methods. Also, XGBoost includes feature selection itself. Morever, to make it easy to call feature selection model, we encapsulate them as standard functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample feature selection function [pcaSelection.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pcaSelection(X_train, y_train, X_test, y_test, verbal = None, returnCoef = False):\n",
    "    '''\n",
    "    choose the feature selection method = 'pca'\n",
    "    fit any feature_selection model with the X_train, y_train\n",
    "    transform the X_train, X_test with the model\n",
    "    do not use the X_test to build feature selection model\n",
    "    \n",
    "    return the selected X_train, X_test\n",
    "    print info of the selecter\n",
    "    return the coef or the score of each feature if asked\n",
    "    '''\n",
    "    #transform to standardscaler\n",
    "    features = X_train.columns.tolist()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "    X_train.columns = features\n",
    "    X_test.columns = features\n",
    "    \n",
    "    pca = PCA(n_components = 40)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    coef = pd.Series()\n",
    "    # featureName = None\n",
    "    \n",
    "    if verbal == True:\n",
    "        print('The total feature number is '+ str(X_train.shape[1]))\n",
    "       # print('The selected feature name is '+ str(featureName))\n",
    "       \n",
    "    if not returnCoef:\n",
    "        return(X_train, X_test)\n",
    "    else:\n",
    "        return(X_train, X_test, coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
